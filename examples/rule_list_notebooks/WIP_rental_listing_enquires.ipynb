{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving Rental Listing Inquiries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Problem Statement:* \n",
    "Predicting apartment rental listing popularity based on the listing content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "# Reference for customizing plots : http://matplotlib.org/users/customizing.html\n",
    "# print(plt.style.available)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Kaggle dataset: \n",
    "# https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries/data\n",
    "\n",
    "### Loading the dataset provided\n",
    "df_train = pd.read_json('../../random/data/rental_listing/train.json')\n",
    "df_test = pd.read_json('../../random/data/rental_listing/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "df_train[\"no_photos\"] = df_train[\"photos\"].apply(len)\n",
    "df_train[\"no_features\"] = df_train[\"features\"].apply(len)\n",
    "df_train[\"created_transformed\"] = pd.to_datetime(df_train[\"created\"])\n",
    "df_train[\"created_yr\"] = df_train[\"created_transformed\"].dt.year\n",
    "df_train[\"created_day\"] = df_train[\"created_transformed\"].dt.day\n",
    "df_train[\"created_month\"] = df_train[\"created_transformed\"].dt.month\n",
    "df_train['created_month_YrMnth'] = 100*df_train[\"created_yr\"] + df_train[\"created_month\"]\n",
    "\n",
    "# Test\n",
    "df_test[\"no_photos\"] = df_test[\"photos\"].apply(len)\n",
    "df_test[\"no_features\"] = df_test[\"features\"].apply(len)\n",
    "df_test[\"created_transformed\"] = pd.to_datetime(df_test[\"created\"])\n",
    "df_test[\"created_yr\"] = df_test[\"created_transformed\"].dt.year\n",
    "df_test[\"created_day\"] = df_test[\"created_transformed\"].dt.day\n",
    "df_test[\"created_month\"] = df_test[\"created_transformed\"].dt.month\n",
    "df_test['created_month_YrMnth'] = 100*df_test[\"created_yr\"] + df_test[\"created_month\"]\n",
    "\n",
    "print(\"Number of rows in Train: {}\".format(df_train.shape))\n",
    "print(\"Number of rows in Test: {}\".format(df_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of class types\")\n",
    "np.unique(df_train['interest_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Starting with numerical features first\n",
    "features_considered = ['bathrooms', 'bedrooms', 'latitude', 'longitude', 'price', \n",
    "                       'no_photos', 'no_features', 'created_yr', 'created_day', 'created_month', \n",
    "                       'created_month_YrMnth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train[features_considered]\n",
    "# Converting 'str' class labels to numeric labels\n",
    "y = df_train['interest_level'].astype('category').cat.codes\n",
    "print(\"Converted Labels: {}\".format(np.unique(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, shuffle=True, stratify=y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "gbm = xgb.XGBClassifier(max_depth=8, n_estimators=500, learning_rate=0.1, n_jobs=-1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10, class_weight=\"balanced\", oob_score=True, random_state=1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train = gbm.predict(X_train)\n",
    "y_hat_val = gbm.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from skater.core.visualizer import decision_boundary as db\n",
    "\n",
    "_, _ = db.plot_decision_boundary(gbm, X0=X_train.iloc[:, 2], X1=X_train.iloc[:, 5], Y=y_train, width=10,\n",
    "                          height=10, static_color_map=['deeppink', 'darkturquoise', 'maroon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, p = db.plot_decision_boundary(gbm, X0=X_train.iloc[:, 2], X1=X_train.iloc[:, 5], Y=y_train, width=10,\n",
    "                          height=10, mode='interactive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"\\n--------Train dataset classification report----------\\n\")\n",
    "target_names = ['high', 'low', 'medium']\n",
    "print(classification_report(y_train, y_hat_train, target_names=target_names))\n",
    "\n",
    "print(\"\\n--------Validation/Holdout dataset classification report----------\\n\")\n",
    "print(classification_report(y_val, y_hat_val, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Skater to understand decision policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skater.core.explanations import Interpretation\n",
    "from skater.model import InMemoryModel\n",
    "from skater.util.dataops import show_in_notebook\n",
    "from skater.util.logger import _INFO\n",
    "\n",
    "\n",
    "interpreter = Interpretation(X_train, feature_names=features_considered)\n",
    "model_inst = InMemoryModel(gbm.predict, examples=X_train, model_type='classifier', unique_values=[0, 1, 2],\n",
    "                           feature_names=features_considered, target_names=['0', '1', '2'], log_level=_INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_explainer = interpreter.tree_surrogate(oracle=model_inst, class_weight=\"balanced\", seed=5)\n",
    "surrogate_explainer.fit(X_train, y_train, use_oracle=True, prune=None, scorer_type='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = surrogate_explainer.predict(X_val)\n",
    "print(\"\\n--------Validation/Holdout dataset classification report----------\\n\")\n",
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "print(classification_report(y_val, y_hat, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "surrogate_explainer.plot_global_decisions(colors=['lightsteelblue', 'darkkhaki', 'aquamarine'], \n",
    "                                          file_name='surrogate_tree_rental_no_prune.png', show_img=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_in_notebook('surrogate_tree_rental_no_prune.png', width=400, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The interactiveness is not that impressive, more works needs to be done there. \n",
    "# This is just a temporary solution\n",
    "show_in_notebook('surrogate_tree_rental_no_prune.png', width=900, height=400 , mode='interactive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\"criterion\": ['gini', 'entropy'], \"min_samples_leaf\": [2, 4],\n",
    "# \"max_leaf_nodes\": [2, 4, 6, 8, 10], \"max_depth\": [4, 6, 10, 14, 18]\n",
    "# }\n",
    "\n",
    "surrogate_explainer.fit(X_train, y_train, use_oracle=True, prune='pre', scorer_type='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_explainer.plot_global_decisions(colors=['lightsteelblue', 'darkkhaki', 'aquamarine'], \n",
    "                                          file_name='surrogate_tree_rental_pruned.png', show_img=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_in_notebook('surrogate_tree_rental_pruned.png', width=400, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_val = surrogate_explainer.predict(X_val)\n",
    "print(\"\\n--------Validation/Holdout dataset classification report----------\\n\")\n",
    "print(classification_report(y_val, y_hat_val, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_explainer2 = interpreter.tree_surrogate(oracle=model_inst, class_weight=\"balanced\", seed=5)\n",
    "surrogate_explainer2.fit(X_train, y_train, use_oracle=True, prune=None, scorer_type='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_val2 = surrogate_explainer2.predict(X_val)\n",
    "print(\"\\n--------Validation/Holdout dataset classification report----------\\n\")\n",
    "print(classification_report(y_val, y_hat_val2, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_explainer2.fit(X_train, y_train, use_oracle=True, prune='post', scorer_type='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The way plotting is done now is slow and not that interactive, this needs to be improved\n",
    "surrogate_explainer2.plot_global_decisions(colors=['lightsteelblue', 'darkkhaki', 'aquamarine'], \n",
    "                                          file_name='surrogate_tree_rental_postpruned.png', show_img=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_in_notebook('surrogate_tree_rental_postpruned.png', width=400, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualization for large graphs needs to be fixed, but in the meantime\n",
    "surrogate_explainer2.decisions_as_txt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat_val2 = surrogate_explainer2.predict(X_val)\n",
    "print(\"\\n--------Validation/Holdout dataset classification report----------\\n\")\n",
    "print(classification_report(y_val, y_hat_val2, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing the scoring function to 'log-loss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interpreter = Interpretation(X_train, feature_names=features_considered)\n",
    "model_inst = InMemoryModel(gbm.predict_proba, examples=X_train, model_type='classifier',\n",
    "                           feature_names=features_considered, target_names=['0', '1', '2'], log_level=_INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "surrogate_explainer3 = interpreter.tree_surrogate(oracle=model_inst, class_weight=\"balanced\", seed=5)\n",
    "surrogate_explainer3.fit(X_train, y_train, use_oracle=True, prune='post', scorer_type='cross_entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat_val3 = surrogate_explainer3.predict(X_val)\n",
    "print(\"\\n--------Validation/Holdout dataset classification report----------\\n\")\n",
    "print(classification_report(y_val, y_hat_val3, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see how a hierarchical Interpretable Tree based model does?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "surrogate_explainer4 = interpreter.tree_surrogate(oracle=model_inst, class_weight=\"balanced\", seed=5)\n",
    "surrogate_explainer4.fit(X_train, y_train, use_oracle=False, prune='post', scorer_type='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat_val4 = surrogate_explainer4.predict(X_val)\n",
    "print(\"\\n--------Validation/Holdout dataset classification report----------\\n\")\n",
    "print(classification_report(y_val, y_hat_val4, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on supplied test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using base estimator\n",
    "X_test = df_test[features_considered]\n",
    "y_hat_test_base_model = gbm.predict_proba(X_test)\n",
    "assert X_test.shape[0] == y_hat_test_base_model.shape[0]\n",
    "\n",
    "y_hat_test_surrogate = surrogate_explainer.predict(X_test, prob_score=True)\n",
    "assert X_test.shape[0] == y_hat_test_surrogate.shape[0]\n",
    "\n",
    "# post + F1 score\n",
    "y_hat_test_surrogate_post_f1 = surrogate_explainer2.predict(X_test, prob_score=True)\n",
    "assert X_test.shape[0] == y_hat_test_surrogate_post_f1.shape[0]\n",
    "\n",
    "# post + log-loss\n",
    "y_hat_test_surrogate_post_ll = surrogate_explainer3.predict(X_test, prob_score=True)\n",
    "assert X_test.shape[0] == y_hat_test_surrogate_post_ll.shape[0]\n",
    "\n",
    "# not trained on the predictions of the base model\n",
    "y_hat_test_surrogate_i = surrogate_explainer4.predict(X_test, prob_score=True)\n",
    "assert X_test.shape[0] == y_hat_test_surrogate_i.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## constructing the format needed for submission\n",
    "list_id = df_test['listing_id'].tolist()\n",
    "# base\n",
    "predictions = pd.DataFrame(y_hat_test_base_model, columns=['high', 'low', 'medium'])\n",
    "result_df_base = predictions\n",
    "result_df_base.loc[:, 'listing_id'] = pd.Series(list_id, index=result_df_base.index)\n",
    "# re-arrange the columns\n",
    "result_df_base = result_df_base[['listing_id', 'high', 'low', 'medium']]\n",
    "\n",
    "# Surrogate\n",
    "predictions = pd.DataFrame(y_hat_test_surrogate, columns=['high', 'low', 'medium'])\n",
    "result_df_surrogate = predictions\n",
    "result_df_surrogate.loc[:, 'listing_id'] = pd.Series(list_id, index=result_df_surrogate.index)\n",
    "# re-arrange the columns\n",
    "result_df_surrogate = result_df_surrogate[['listing_id', 'high', 'low', 'medium']]\n",
    "\n",
    "# post + F1 score\n",
    "predictions = pd.DataFrame(y_hat_test_surrogate_post_f1, columns=['high', 'low', 'medium'])\n",
    "result_df_surrogate_post_f1 = predictions\n",
    "result_df_surrogate_post_f1.loc[:, 'listing_id'] = pd.Series(list_id, index=result_df_surrogate_post_f1.index)\n",
    "# re-arrange the columns\n",
    "result_df_surrogate_post_f1 = result_df_surrogate_post_f1[['listing_id', 'high', 'low', 'medium']]\n",
    "\n",
    "# post + log-loss\n",
    "predictions = pd.DataFrame(y_hat_test_surrogate_post_ll, columns=['high', 'low', 'medium'])\n",
    "result_df_surrogate_post_ll = predictions\n",
    "result_df_surrogate_post_ll.loc[:, 'listing_id'] = pd.Series(list_id, index=result_df_surrogate_post_ll.index)\n",
    "# re-arrange the columns\n",
    "result_df_surrogate_post_ll = result_df_surrogate_post_ll[['listing_id', 'high', 'low', 'medium']]\n",
    "\n",
    "\n",
    "# a better interpretable tree using post-pruning\n",
    "predictions = pd.DataFrame(y_hat_test_surrogate_i, columns=['high', 'low', 'medium'])\n",
    "result_df_surrogate_i = predictions\n",
    "result_df_surrogate_i.loc[:, 'listing_id'] = pd.Series(list_id, index=result_df_surrogate_i.index)\n",
    "# re-arrange the columns\n",
    "result_df_surrogate_i = result_df_surrogate_i[['listing_id', 'high', 'low', 'medium']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# converting to csv\n",
    "result_df_base.to_csv('submission_base.csv', index=False)\n",
    "# Using surrogate models for predicting didn't give good result but nevertheless could possibly be used\n",
    "# for explaining the decisions approximately\n",
    "result_df_surrogate.to_csv('submission_surrogate.csv', index=False)\n",
    "result_df_surrogate_post_f1.to_csv('submission_post_f1.csv', index=False)\n",
    "result_df_surrogate_post_ll.to_csv('submission_post_ll.csv', index=False)\n",
    "\n",
    "# interpretable model without using predictions from the base model(Oracle) didn't help either in this case\n",
    "result_df_surrogate_i.to_csv('submission_i.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
